{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baba1\\AppData\\Roaming\\Python\\Python37\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*- # 設定編碼方式為UTF-8\n",
    "\n",
    "# 載入相關套件\n",
    "from ckip_transformers.nlp import CkipWordSegmenter, CkipNerChunker  # 從ckip_transformers.nlp中載入相應模組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing drivers ... WS\n",
      "Initializing drivers ... NER\n",
      "Initializing drivers ... all done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 初始化 drivers\n",
    "print(\"Initializing drivers ... WS\")  # 印出初始化Word Segmenter的訊息\n",
    "ws_driver = CkipWordSegmenter(model=\"albert-base\")  # 初始化Word Segmenter\n",
    "print(\"Initializing drivers ... NER\")  # 印出初始化NER Chunker的訊息\n",
    "ner_driver = CkipNerChunker(model=\"albert-base\")  # 初始化NER Chunker\n",
    "print(\"Initializing drivers ... all done\")  # 印出初始化完成的訊息\n",
    "print()  # 印出空行，增加可讀性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(sentence_ws): #定義一個名為clean的函數，用於清洗斷詞結果\n",
    "  short_sentence = []  # 初始化一個空串列short_sentence，用於儲存短詞\n",
    "  for word_ws in sentence_ws:  # 逐詞進行處理\n",
    "    # 只剩一個字的詞也不留\n",
    "    is_not_one_charactor = not (len(word_ws) == 1)  # 判斷是否只有一個字母\n",
    "\n",
    "    # 符合條件的詞加入串列\n",
    "    if is_not_one_charactor:\n",
    "      short_sentence.append(f\"{word_ws}\")  # 將短詞加入short_sentence串列\n",
    "\n",
    "  return (\" \".join(short_sentence))  # 返回處理後的短詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    text = [\n",
    "        '經過多年激烈戰事，複製人大戰即將結束。絶地議會派歐比王將導致戰亂的主謀者繩之以法；不料，西斯勢力已悄悄深入銀河系，勢力漸大的議長白卜庭用黑暗勢力的力量，誘惑天行者安納金轉變成黑武士達斯維達，幫助他達成心願建立銀河帝國，剷除絕地武士…【星際大戰】系列電影最後一塊拼圖，喬治盧卡斯不僅要解開黑武士的影壇跨世紀謎團，更要著手打造影史最大星際戰爭。',\n",
    "    ]\n",
    "    ws = ws_driver(text)  # 進行斷詞\n",
    "    ner = ner_driver(text)  # 進行NER\n",
    "\n",
    "    print()  # 印出空行，增加可讀性\n",
    "    print('=====')  # 印出分隔線\n",
    "    for sentence, sentence_ws, sentence_ner in zip(text, ws, ner):  # 逐句進行處理\n",
    "        print(\"原文：\")\n",
    "        print(sentence)  # 印出原文\n",
    "        short = clean(sentence_ws)  # 呼叫clean函數進行處理\n",
    "        print(\"斷詞後：\")\n",
    "        print(short)  # 印出斷詞後的短詞\n",
    "        print(\"NER：\")\n",
    "        print(sentence_ner)  # 印出NER結果\n",
    "        print('=====')  # 印出分隔線"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====\n",
      "原文：\n",
      "經過多年激烈戰事，複製人大戰即將結束。絶地議會派歐比王將導致戰亂的主謀者繩之以法；不料，西斯勢力已悄悄深入銀河系，勢力漸大的議長白卜庭用黑暗勢力的力量，誘惑天行者安納金轉變成黑武士達斯維達，幫助他達成心願建立銀河帝國，剷除絕地武士…【星際大戰】系列電影最後一塊拼圖，喬治盧卡斯不僅要解開黑武士的影壇跨世紀謎團，更要著手打造影史最大星際戰爭。\n",
      "斷詞後：\n",
      "經過 激烈 戰事 複製人 大戰 即將 結束 絶地 議會 派歐比王將 導致 戰亂 主謀 繩之以法 不料 西斯 勢力 悄悄 深入 銀河系 勢力 議長 白卜庭 黑暗 勢力 力量 誘惑 天行 安納金 轉變成 黑武士 達斯維達 幫助 達成 心願 建立 銀河 帝國 剷除 絕地 武士 星際 大戰 系列 電影 最後 拼圖 喬治盧卡斯 不僅 解開 黑武士 影壇 世紀 謎團 著手 打造 影史 星際 戰爭\n",
      "NER：\n",
      "[NerToken(word='多年', ner='DATE', idx=(2, 4)), NerToken(word='歐比王', ner='PERSON', idx=(24, 27)), NerToken(word='西斯', ner='PERSON', idx=(44, 46)), NerToken(word='銀河系', ner='ORG', idx=(53, 56)), NerToken(word='白卜庭', ner='PERSON', idx=(64, 67)), NerToken(word='安納金', ner='PERSON', idx=(81, 84)), NerToken(word='銀河帝國', ner='GPE', idx=(104, 108)), NerToken(word='喬治盧卡斯', ner='PERSON', idx=(133, 138))]\n",
      "=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()  # 呼叫main函數執行主程序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CKIP_NER標記解釋\n",
    "\n",
    "![Alt text](image-2.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
